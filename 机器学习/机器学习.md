# Chapter01 机器学习总览

人工智能>机器学习>深度学习



## Concepts

**Loss Function**

衡量模型和样本点的差异(距离), 使问题转变为最小化问题

0-1损失函数(0-1 lossfunction):

平方损失函数(quadraticloss function)

绝对损失函数(absoluteloss function)

对数损失函数(logarithmicloss function)

**梯度下降**

求解 Loss Function 最小值对应参数.

learning rate





## 学习

### supervised learning有监督学习

1. 判别分类
   
   1. 线性模型
   
   2. 非线性模型
      
      1. 深度学习
      
      2. SVM
      
      3. K-NN
      
      4. 决策树

2. 回归Regression

### half supervised learning半监督学习

### no supervised learning无监督学习

1. 聚类

### 迁移学习



### Reinforcement Learning 强化学习



### Pre-trained Model ( Foundation Model)





---



## 模型训练

1. **把数据集全部作为训练集，然后用训练集训练模型，用训练集验证模型（如果有多个模型需要进行选择，那么最后选出训练误差最小的那个模型作为最好的模型）**

2. **第二种方式：把数据集随机分为训练集和测试集，然后用训练集训练模型，用测试集验证模型（如果有多个模型需要进行选择，那么最后选出测试误差最小的那个模型作为最好的模型）**

3. **把数据集随机分为训练集，验证集和测试集，然后用训练集训练模型，用验证集验证模型，根据情况不断调整模型，选择出其中最好的模型，再用训练集和验证集数据训练出一个最终的模型，最后用测试集评估最终的模型**

4. **交叉验证（Cross Validation）简单来说就是重复使用数据。除去测试集，把剩余数据进行划分，组合成多组不同的训练集和验证集，某次在训练集中出现的样本下次可能成为验证集中的样本，这就是所谓的“交叉”。最后用各次验证误差的平均值作为模型最终的验证误差。**
   
   1. **留一法（Leave One Out Cross Validation，LOOCV）**
      假设数据集一共有m个样本，依次从数据集中选出1个样本作为验证集，其余m-1个样本作为训练集，这样进行m次单独的模型训练和验证，最后将m次验证结果取平均值，作为此模型的验证误差。
      留一法的优点是结果近似无偏，这是因为几乎所有的样本都用于模型的拟合。缺点是计算量大。一般在实际运用中我们不太用留一法。
   
   2. **K折交叉验证（K-Fold Cross Validation）**
   
   把数据集分成K份，每个子集互不相交且大小相同，依次从K份中选出1份作为验证集，其余K-1份作为训练集，这样进行K次单独的模型训练和验证，最后将K次验证结果取平均值，作为此模型的验证误差。当K=m时，就变为留一法。可见留一法是K折交叉验证的特例。
   根据经验，K一般取10。（在各种真实数据集上进行实验发现，10折交叉验证在偏差和方差之间取得了最佳的平衡。）
   
   3. **多次K折交叉验证（Repeated K-Fold Cross Validation）**
   
   每次用不同的划分方式划分数据集，每次划分完后的其他步骤和K折交叉验证一样。例如：10 次 10 折交叉验证，即每次进行10次模型训练和验证，这样一共做10次，也就是总共做100次模型训练和验证，最后将结果平均。这样做的目的是让结果更精确一些。（研究发现，重复K折交叉验证可以提高模型评估的精确度，同时保持较小的偏差。）
   
   4. **蒙特卡洛交叉验证（Monte Carlo Cross Validation）**
   
   即将留出法（holdout）进行多次。每次将数据集随机划分为训练集和验证集，这样进行多次单独的模型训练和验证，最后将这些验证结果取平均值，作为此模型的验证误差。与单次验证（holdout）相比，这种方法可以更好地衡量模型的性能。与K折交叉验证相比，这种方法能够更好地控制模型训练和验证的次数，以及训练集和验证集的比例。缺点是有些观测值可能从未被选入验证子样本，而有些观测值可能不止一次被选中。（偏差大，方差小）
   
   

---











## Generative Adversarial Network

给定输出组和输出组,无需给出之间的关系.



## Anomaly Detection 异常检测



## Exlpainable AI



## Model Attack



## Domain Adaptation



## Network Compression

模型压缩

## Life-long Learning



## Meta Learning

机器自己发现算法

- few shot learning 使用少量数据
  
  
  
  

## Chat GPT

## VAE



## Diffusion Model
