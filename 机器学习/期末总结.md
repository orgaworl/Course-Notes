## 梯度下降方法

1. 随次数减小

2. Adagrad

3. RMSProp

4. Momentum

5. Adam

6. 随机梯度下降

7. Batch

---

## RNN

**梯度**

- clipping技术解决梯度爆炸.

- LSTM 防止梯度消失.
  
  forget gate设置高bias, 保证在多数情况下开启

**tec**

- GRU： 比LSTM更简化, 参数少，训练快，避免过拟合。

- Clockwise RNN

- Structurally Constrained RN

**RNN 应用**

1. 多对一
   
   - 语义分析
   
   - 关键词提取

2. 多对多(输出较短)
   
   - 语音识别
     
     CTC(Connectionist Temporal Classification)解决叠词问题

3. 多对多(输出长度不确定)
   
   - 语法解析

---

## Semi-supervised

### 2.3 半监督学习的三个基本假设

目前，在半监督学习中有三个常用的基本假设来建立预测样例和学习目标之间的关系，有以下三个：

（1）平滑假设(Smoothness Assumption)：位于稠密数据区域的两个距离很近的样例的类标签相似，也就是说，当两个样例被稠密数据区域中的边连接时，它们在很大的概率下有相同的类标签；相反地，当两个样例被稀疏数据区域分开时，它们的类标签趋于不同。

（2）聚类假设(Cluster Assumption)：当两个样例位于同一聚类簇时，它们在很大的概率下有相同的类标签。这个假设的等价定义为低密度分离假设(Low Sensity
 Separation Assumption)，即分类决策边界应该穿过稀疏数据区域，而避免将稠密数据区域的样例分到决策边界两侧。

（3）流形假设(Manifold Assumption)：将高维数据嵌入到低维流形中，当两个样例位于低维流形中的一个小局部邻域内时，它们具有相似的类标签。

### 2.4.1 半监督学习分类

（１）半监督分类 （Semi-Supervised Classification）  

在无类标签的样例的帮助下训练有类标 签的样本，获得比只用有类标签的样本训练得到的分类器性能更优的分类器，弥补有类标签的样本不足的缺陷，其中类标签yi取有限离散值yi∈{c1,c2,···,cc},cj∈N。

（２）半监督回归（Semi-Supervised Regression）  

在无输出的输入的帮助下训练有输出的输入，获得比只用有输出的输入训练得到的回归器性能更好的回归器，其中输出yi 取连续值 yi∈Ｒ。

（３）半监督聚类（Semi-Supervised Clustering）  

在有类标签的样本的信息帮助下获得比只用无类标 签的样例得到的结果更好的簇，提高聚类方法的精度。

（４）半监督降维（Semi-Supervised Dimensionality Reduction）  

在有类标签的样本的信息帮助下找到高维输入数据的低维结构，同时保持原始高维数据和成对约束（Pair-Wise Constraints）的结构不变，即在高维空间中满足正约束（Must-Link Constraints）的样例在低维空间中相距很近，在高维空间中满足负约束（Cannot-Link Constraints）的样例在低维空间中距离很远。

### 2.4.2 半监督学习方法

一般，半监督学习算法可分为：**self-training（自训练算法）**、**Graph-based Semi-supervised Learning（基于图的半监督算法）**、**Semi-supervised supported vector machine（半监督支持向量机，S3VM）**。简单介绍如下：

- 1.简单自训练（simple self-training）：**用有标签数据训练一个分类器，然后用这个分类器对无标签数据进行分类，这样就会产生伪标签（pseudo label）或软标签（soft label），挑选你认为分类正确的无标签样本（此处应该有一个挑选准则），把选出来的无标签样本用来训练分类器。**

- 2.协同训练（co-training）：其实也是 self-training 的一种，但其思想是好的。假设每个数据可以从不同的角度（view）进行分类，不同角度可以训练出不同的分类器，然后用这些从不同角度训练出来的分类器对无标签样本进行分类，再选出认为可信的无标签样本加入训练集中。由于这些分类器从不同角度训练出来的，可以形成一种互补，而提高分类精度；就如同从不同角度可以更好地理解事物一样。

- 3.半监督字典学习：其实也是 self-training 的一种，先是用有标签数据作为字典，对无标签数据进行分类，挑选出你认为分类正确的无标签样本，加入字典中（此时的字典就变成了半监督字典了）

- 4.标签传播算法（Label Propagation Algorithm）：是一种基于图的半监督算法，通过构造图结构（数据点为顶点，点之间的相似性为边）来寻找训练数据中有标签数据和无标签数据的关系。是的，只是训练数据中，这是一种直推式的半监督算法，即只对训练集中的无标签数据进行分类，这其实感觉很像一个有监督分类算法…，但其实并不是，因为其标签传播的过程，会流经无标签数据，即有些无标签数据的标签的信息，是从另一些无标签数据中流过来的，这就用到了无标签数据之间的联系

- 5.半监督支持向量机：监督支持向量机是利用了结构风险最小化来分类的，半监督支持向量机还用上了无标签数据的空间分布信息，即决策超平面应该与无标签数据的分布一致（应该经过无标签数据密度低的地方）（这其实是一种假设，不满足的话这种无标签数据的空间分布信息会误导决策超平面，导致性能比只用有标签数据时还差）

其实，半监督学习的方法大都建立在对数据的某种假设上，只有满足这些假设(也就是上面提到的半监督学习的三个基本假设)，半监督算法才能有性能的保证，这也是限制了半监督学习应用的一大障碍。

---

## Self-supervised

---

## AI-Security
